<!doctype html><html lang="en"><head><meta charset="UTF-8" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><title>Path: Transformer Foundations | ScholarNotion</title><link rel="stylesheet" href="/assets/css/styles.css" /></head><body><header class="site-header"><div class="container nav"><a class="brand" href="/">ScholarNotion</a><nav class="menu"><a href="/pages/topics.html">Topics</a><a href="/pages/charts.html">Charts</a><a href="/pages/insights.html">Insights</a><a href="/pages/explorer.html">Explorer</a><a href="/pages/methodology.html">Methodology</a></nav><a class="search-chip" href="/pages/charts.html">Search data</a></div></header><main class="container"><section class="page-title"><h1>Learning Path: Transformer Foundations</h1><p>Suggested completion: 2 weeks for readers with math and probability basics.</p></section><section class="section"><article class="card"><h3>Roadmap (10 concepts)</h3><ol class="list"><li>Tokenization</li><li>Embedding</li><li>Self-Attention</li><li>Multi-Head Attention</li><li>Positional Encoding</li><li>Feed-Forward Blocks</li><li>Residual and LayerNorm</li><li>Autoregressive Training</li><li>Evaluation Metrics</li><li>Scaling Laws</li></ol></article></section><section class="section"><a class="button" href="/pages/concept-transformer.html">Start path</a></section></main></body></html>
